{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import bs4\n",
    "import os\n",
    "import sqlite3\n",
    "import threading\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set SCRAPE=True in order to download the data from FB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCRAPE = True\n",
    "\n",
    "UNIFIED_JSON_PATH = \"posts.json\"\n",
    "LOGGING_INTERVAL = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TOKEN = \"EAACEdEose0cBAIrulgRfAlSs4E9j2pqIuf9MGwNAG6mxke8XvXpH3WEUHsZBKPQOHN8hZBe8iCeVKKNc2XVrkx87Ju4ZBujPm25CJ8wrpNwp5PnZCaHLtN91w0ok2AUZApkI7zZCpCnw9kZB2erv1GoHci50fZBE5wVGmZAZAAZB1qTrX94nTHddKciCW6zTZBZAZB7UIZD\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to return an empty list if string is not JSON formatted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    try:\n",
    "        return json.loads(open(path, \"r\").read())\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        return []\n",
    "\n",
    "def json_append(path, post):\n",
    "    data = read_json(path)\n",
    "    data.append(post)\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(json.dumps(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a supplemental function to simplify API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get(url_):\n",
    "    return json.loads(requests.get(url_).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define gruop ID variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TECHNION_CONFESSIONS_ID = \"134517547222780\"      # Technion - Haifa\n",
    "TAU_CONFESSIONS_ID = \"561380070875128\"           # Tel Aviv University\n",
    "IDC_CONFESSIONS_ID = \"199527394120566\"           # Beintchumi - Herzlia\n",
    "HUJI_CONFESSIONS_ID = \"323288791493138\"          # Hebrew University - Jerusalem\n",
    "BGU_CONFESSIONS_ID = \"151003595697352\"           # Ben Gurion University - Beer Sheva\n",
    "ARIEL_CONFESSIONS_ID = \"465435713853175\"         # Ariel University\n",
    "HAIFA_CONFESSIONS_ID = \"417201845375921\"         # Haifa University\n",
    "HADASSAH_CONFESSIONS_ID = \"2044836585541512\"     # Hadassah\n",
    "ORT_BRAUDE_CONFESSIONS_ID = \"1453869761388065\"   # Ort-Braude\n",
    "BAR_ILAN_CONFESSIONS_ID = \"2124618411093048\"     # Bar-Ilan\n",
    "MTA_CONFESSIONS_ID = \"157123741522094\"           # Tel Aviv-Yafo Academy\n",
    "YIZRAEL_CONFESSIONS_ID = \"1758687200848633\"      # Yizrael Valley Academy\n",
    "IDF_CONFESSIONS_ID = \"332027507300337\"           # IDF\n",
    "HOGWARTS_CONFESSIONS_ID = \"1685757288142526\"     # Hogwarts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authenticate to Graph API - it is preferred to use manual token from Graph API Explorer because it has better permissions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s = \"6cc937f2a9dbc9df92600f365c777d1a\"\n",
    "# i = \"652869818252649\"\n",
    "# u = \"https://graph.facebook.com/oauth/access_token?client_id={id}&client_secret={secret}&grant_type=client_credentials\"\n",
    "\n",
    "# TOKEN = get(u.format(id=i, secret=s))['access_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Graph API host and API node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOST = \"https://graph.facebook.com/\"\n",
    "API_NODE = \"v2.12/\"\n",
    "QUERY = \"?fields=created_time,message_tags,message,shares,reactions.type(LIKE).limit(0).summary(1).as(like),reactions.type(LOVE).limit(0).summary(1).as(love),reactions.type(HAHA).limit(0).summary(1).as(haha),reactions.type(WOW).limit(0).summary(1).as(wow),reactions.type(SAD).limit(0).summary(1).as(sad),reactions.type(ANGRY).limit(0).summary(1).as(angry)&limit=10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a list of the pages that are going to be scraped in a manner of (id, alias) tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAGES = [\n",
    "    (TECHNION_CONFESSIONS_ID, \"TECHNION\"),\n",
    "    (TAU_CONFESSIONS_ID, \"TAU\"),\n",
    "    (IDC_CONFESSIONS_ID, \"IDC\"),\n",
    "    (HUJI_CONFESSIONS_ID, \"HUJI\"),\n",
    "    (BGU_CONFESSIONS_ID, \"BGU\"),\n",
    "    (ARIEL_CONFESSIONS_ID, \"ARIEL\"),\n",
    "    (HAIFA_CONFESSIONS_ID, \"HAIFA\"),\n",
    "    (HADASSAH_CONFESSIONS_ID, \"HADASSAH\"),\n",
    "    (ORT_BRAUDE_CONFESSIONS_ID, \"BRAUDE\"),\n",
    "    (BAR_ILAN_CONFESSIONS_ID, \"BIU\"),\n",
    "    (MTA_CONFESSIONS_ID, \"MTA\"),\n",
    "    (YIZRAEL_CONFESSIONS_ID, \"YIZRAEL\"),\n",
    "    (IDF_CONFESSIONS_ID, \"IDF\"),\n",
    "    (HOGWARTS_CONFESSIONS_ID, \"HOGWARTS\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Container for the scraped posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "posts = []\n",
    "last_pages = {}  # This is intended for adding more posts without calling for scraped pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a supplemental builder functions for the API calls' URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_url(page_id):\n",
    "    return HOST + API_NODE + page_id + \"/posts\" + QUERY + \"&access_token={}\".format(TOKEN)\n",
    "\n",
    "def build_comments_url(post_id):\n",
    "    return HOST + API_NODE + post_id + \"/comments\" + QUERY + \"&access_token={}\".format(TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that scrapes a general object (post or comment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_object(raw_object, object_type, object_source, parent_id=None):\n",
    "    obj = {}   \n",
    "    \n",
    "    obj['type'] = object_type\n",
    "    obj['source'] = object_source\n",
    "    \n",
    "    obj['id'] = raw_object['id']\n",
    "    obj['parent_id'] = parent_id\n",
    "    \n",
    "    try:\n",
    "        obj['message'] = raw_object['message']\n",
    "    except KeyError:\n",
    "        obj['message'] = ''\n",
    "\n",
    "    obj['created_time'] = raw_object['created_time']\n",
    "\n",
    "    like = raw_object[\"like\"][\"summary\"][\"total_count\"]\n",
    "    love = raw_object[\"love\"][\"summary\"][\"total_count\"]\n",
    "    haha = raw_object[\"haha\"][\"summary\"][\"total_count\"]\n",
    "    wow = raw_object[\"wow\"][\"summary\"][\"total_count\"]\n",
    "    sad = raw_object[\"sad\"][\"summary\"][\"total_count\"]\n",
    "    angry = raw_object[\"angry\"][\"summary\"][\"total_count\"]\n",
    "\n",
    "    obj['like'] = like\n",
    "    obj['love'] = love\n",
    "    obj['haha'] = haha\n",
    "    obj['wow'] = wow\n",
    "    obj['sad'] = sad\n",
    "    obj['angry'] = angry\n",
    "    \n",
    "    obj['total_reactions'] = sum([like, love, haha, wow, sad, angry])\n",
    "    \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a fumction that will paginate through the posts of a URL and scrape them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_posts(url, source):\n",
    "    res = get(url)\n",
    "    if 'data' in res:\n",
    "        for i, raw_post in enumerate(res['data']):\n",
    "            post = query_object(raw_post, \"POST\", source)\n",
    "            posts.append(post)\n",
    "            if len(posts) % LOGGING_INTERVAL == 0:\n",
    "                print(\"{} is on item #{}\".format(source, len(posts)))\n",
    "    if 'paging' in res:\n",
    "        if 'next' in res['paging']:\n",
    "            last_pages[source] = url\n",
    "            return get_posts(res['paging']['next'], source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_tag(raw_tag, parent_id, parent_source):\n",
    "    tag = {}\n",
    "    \n",
    "    tag[\"parent_id\"] = parent_id\n",
    "    tag[\"source\"] = parent_source\n",
    "    tag[\"type\"] = \"TAG\"\n",
    "    \n",
    "    try:\n",
    "        tag[\"tagged_user_id\"] = raw_tag[\"id\"]\n",
    "    except KeyError:\n",
    "        tag[\"tagged_user_id\"] = None\n",
    "        \n",
    "    try:\n",
    "        tag[\"tagged_user_name\"] = raw_tag[\"name\"]\n",
    "    except KeyError:\n",
    "        tag[\"tagged_user_name\"] = None\n",
    "            \n",
    "    \n",
    "    try:\n",
    "        tag[\"tagged_user_type\"] = raw_tag[\"type\"]\n",
    "    except KeyError:\n",
    "        tag[\"tagged_user_type\"] = None\n",
    "            \n",
    "    \n",
    "    return tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that will call the API for each post comments, scrape them and get their tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_post_comments(url, post_id, post_source):\n",
    "    json_path = \"{}.json\".format(post_source)\n",
    "    res = get(url)\n",
    "    if 'data' in res:\n",
    "        for raw_comment in res['data']:\n",
    "            comment = query_object(raw_comment, \"COMMENT\", post_source, parent_id=post_id)\n",
    "            posts.append(comment)\n",
    "            \n",
    "            if raw_comment.get(\"message_tags\"):\n",
    "                for raw_tag in raw_comment.get(\"message_tags\"):\n",
    "                    tag = parse_tag(raw_tag, raw_comment[\"id\"], post_source)\n",
    "                    posts.append(tag)\n",
    "            \n",
    "            if len(posts) % LOGGING_INTERVAL == 0:\n",
    "                print(\"{} is on item #{}\".format(post_source, len(posts)))\n",
    "            \n",
    "    if 'paging' in res:\n",
    "        if 'next' in res['paging']:\n",
    "            return get_post_comments(res['paging']['next'], post_id, post_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, create a function that will scrapes all of the posts' comments and comment tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    n = max(1, n)\n",
    "    return (l[i:i+n] for i in range(0, len(l), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_comments(posts_list):\n",
    "    for post in posts_list:\n",
    "        get_post_comments(build_comments_url(post[\"id\"]), post[\"id\"], post[\"source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use threading to query each Facebook Group in a different thread - this is the worker funciton:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If SCRAPE, the script will run the threads (stop them using >>taskkill /f /im -\"python.exe\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAIFA is on item #250\n",
      "BRAUDE is on item #500\n",
      "HADASSAH is on item #750\n",
      "HADASSAH is on item #1000\n",
      "HUJI is on item #1250\n",
      "ARIEL is on item #1500\n",
      "TECHNION is on item #1750\n",
      "IDF is on item #2000\n",
      "TAU is on item #2250\n",
      "ARIEL is on item #2500\n",
      "ARIEL is on item #2750\n",
      "TAU is on item #3000\n",
      "HOGWARTS is on item #3250\n",
      "ARIEL is on item #3500\n",
      "BGU is on item #3750\n",
      "HADASSAH is on item #4000\n",
      "HOGWARTS is on item #4250\n",
      "IDF is on item #4500\n",
      "BGU is on item #4750\n",
      "TAU is on item #5000\n",
      "BRAUDE is on item #5250\n",
      "HAIFA is on item #5500\n",
      "IDC is on item #5750\n",
      "TAU is on item #6000\n",
      "HADASSAH is on item #6250\n",
      "ARIEL is on item #6500\n",
      "HAIFA is on item #6750\n",
      "TAU is on item #7000\n",
      "ARIEL is on item #7250\n",
      "HUJI is on item #7500\n",
      "TECHNION is on item #7750\n",
      "HUJI is on item #8000\n",
      "ARIEL is on item #8250\n",
      "ARIEL is on item #8500\n",
      "BIU is on item #8750\n",
      "BIU is on item #9000\n",
      "BIU is on item #9250\n"
     ]
    }
   ],
   "source": [
    "if SCRAPE:\n",
    "    \n",
    "    threads = []\n",
    "    \n",
    "    for node, name in PAGES:\n",
    "        t = threading.Thread(target=get_posts, args=(build_url(node), name,))\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "    \n",
    "    for t in threads:\n",
    "        t.join()\n",
    "        \n",
    "else:\n",
    "    posts = pd.read_csv(\"posts.csv\").to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"posts.json\", \"w\") as f:\n",
    "    f.write(json.dumps(posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[II] Scraping comments...\n",
      "IDC is on item #9500\n",
      "BGU is on item #10000\n",
      "BGU is on item #10250\n",
      "TAU is on item #10750\n",
      "IDC is on item #11250\n",
      "HUJI is on item #11500\n",
      "TAU is on item #11750\n",
      "HADASSAH is on item #12000\n",
      "IDF is on item #12500\n",
      "BGU is on item #13500\n",
      "HADASSAH is on item #13750\n",
      "ARIEL is on item #14500\n",
      "ARIEL is on item #14750\n",
      "TECHNION is on item #15250\n"
     ]
    }
   ],
   "source": [
    "if SCRAPE:\n",
    "    \n",
    "    threads = []\n",
    "    \n",
    "    print(\"[II] Scraping comments...\")\n",
    "    for posts_list in chunks(posts, 20):\n",
    "        t = threading.Thread(target=get_comments, args=(posts_list,))\n",
    "        threads.append(t)\n",
    "        t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-97:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Python3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-42-22c8534da172>\", line 3, in get_comments\n",
      "    get_post_comments(build_comments_url(post[\"id\"]), post[\"id\"], post[\"source\"])\n",
      "  File \"<ipython-input-40-2469a39ebf38>\", line 3, in get_post_comments\n",
      "    res = get(url)\n",
      "  File \"<ipython-input-30-183a6e4ee947>\", line 2, in get\n",
      "    return json.loads(requests.get(url_).text)\n",
      "  File \"C:\\Python3\\lib\\json\\__init__.py\", line 354, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"C:\\Python3\\lib\\json\\decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"C:\\Python3\\lib\\json\\decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "Exception in thread Thread-45:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Python3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-42-22c8534da172>\", line 3, in get_comments\n",
      "    get_post_comments(build_comments_url(post[\"id\"]), post[\"id\"], post[\"source\"])\n",
      "  File \"<ipython-input-40-2469a39ebf38>\", line 3, in get_post_comments\n",
      "    res = get(url)\n",
      "  File \"<ipython-input-30-183a6e4ee947>\", line 2, in get\n",
      "    return json.loads(requests.get(url_).text)\n",
      "  File \"C:\\Python3\\lib\\json\\__init__.py\", line 354, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"C:\\Python3\\lib\\json\\decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"C:\\Python3\\lib\\json\\decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "Exception in thread Thread-337:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Python3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-42-22c8534da172>\", line 3, in get_comments\n",
      "    get_post_comments(build_comments_url(post[\"id\"]), post[\"id\"], post[\"source\"])\n",
      "  File \"<ipython-input-40-2469a39ebf38>\", line 3, in get_post_comments\n",
      "    res = get(url)\n",
      "  File \"<ipython-input-30-183a6e4ee947>\", line 2, in get\n",
      "    return json.loads(requests.get(url_).text)\n",
      "  File \"C:\\Python3\\lib\\json\\__init__.py\", line 354, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"C:\\Python3\\lib\\json\\decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"C:\\Python3\\lib\\json\\decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not SCRAPE:\n",
    "    import pandas as pd\n",
    "    import sqlite3\n",
    "\n",
    "    df = pd.read_sql(\"select * from posts\", sqlite3.connect(\"data.db\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract manual post id from the posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angry</th>\n",
       "      <th>created_time</th>\n",
       "      <th>haha</th>\n",
       "      <th>id</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>message</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>sad</th>\n",
       "      <th>source</th>\n",
       "      <th>tagged_user_id</th>\n",
       "      <th>tagged_user_name</th>\n",
       "      <th>tagged_user_type</th>\n",
       "      <th>total_reactions</th>\n",
       "      <th>type</th>\n",
       "      <th>wow</th>\n",
       "      <th>page_id</th>\n",
       "      <th>reply_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-02-22T07:00:00+0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134517547222780_148184599189408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>מאז הסמסטר הראשון מלווה אותי תחושת חוסר ביטחו...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TECHNION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>POST</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#3062</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-02-22T06:45:00+0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134517547222780_148184395856095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>תמיד מרגיש לי שהבחור שאיתי נמשך אלי הרבה יותר...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TECHNION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POST</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#3061</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-02-22T06:30:00+0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134517547222780_148184269189441</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>תמיד במהלך היום אני מרגיש סבבה אבל בערב, כשאנ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TECHNION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>POST</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#3060</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-02-22T06:15:00+0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>134517547222780_148184105856124</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>יש אצלי בחור במעונות שכנראה אין לו מבחנים... ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TECHNION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>POST</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#3059</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-02-22T06:00:00+0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134517547222780_148146599193208</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>אני מרגישה שמאז שאני בטכניון הגישה שלי כלפי א...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TECHNION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>POST</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#3058</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   angry              created_time  haha                               id  \\\n",
       "0    0.0  2018-02-22T07:00:00+0000   0.0  134517547222780_148184599189408   \n",
       "1    0.0  2018-02-22T06:45:00+0000   0.0  134517547222780_148184395856095   \n",
       "2    0.0  2018-02-22T06:30:00+0000   0.0  134517547222780_148184269189441   \n",
       "3    0.0  2018-02-22T06:15:00+0000   3.0  134517547222780_148184105856124   \n",
       "4    0.0  2018-02-22T06:00:00+0000   0.0  134517547222780_148146599193208   \n",
       "\n",
       "   like  love                                            message parent_id  \\\n",
       "0   0.0   0.0   מאז הסמסטר הראשון מלווה אותי תחושת חוסר ביטחו...      None   \n",
       "1   0.0   0.0   תמיד מרגיש לי שהבחור שאיתי נמשך אלי הרבה יותר...      None   \n",
       "2   2.0   1.0   תמיד במהלך היום אני מרגיש סבבה אבל בערב, כשאנ...      None   \n",
       "3   7.0   0.0   יש אצלי בחור במעונות שכנראה אין לו מבחנים... ...      None   \n",
       "4   6.0   0.0   אני מרגישה שמאז שאני בטכניון הגישה שלי כלפי א...      None   \n",
       "\n",
       "   sad    source tagged_user_id tagged_user_name tagged_user_type  \\\n",
       "0  1.0  TECHNION            NaN              NaN              NaN   \n",
       "1  0.0  TECHNION            NaN              NaN              NaN   \n",
       "2  0.0  TECHNION            NaN              NaN              NaN   \n",
       "3  0.0  TECHNION            NaN              NaN              NaN   \n",
       "4  0.0  TECHNION            NaN              NaN              NaN   \n",
       "\n",
       "   total_reactions  type  wow page_id reply_to  \n",
       "0              1.0  POST  0.0   #3062      NaN  \n",
       "1              0.0  POST  0.0   #3061      NaN  \n",
       "2              3.0  POST  0.0   #3060      NaN  \n",
       "3             10.0  POST  0.0   #3059      NaN  \n",
       "4              6.0  POST  0.0   #3058      NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_REGEX = \"(#\\d+|\\d+#){1}\"\n",
    "df[\"page_id\"] = df[\"message\"].str.findall(ID_REGEX).str.get(0)\n",
    "df[\"message\"].str\n",
    "df[\"reply_to\"] = df[\"message\"].str.findall(ID_REGEX).str.get(1)\n",
    "df[\"message\"] = df[\"message\"].str.replace(ID_REGEX, \"\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a clean message column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['clean_message'] = df['message'].str.replace(\"[^א-ת ]\", \"\")\n",
    "df['clean_message'] = df['clean_message'].str.replace(\"[\\s]\", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export to SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-175:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Python3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-42-22c8534da172>\", line 3, in get_comments\n",
      "    get_post_comments(build_comments_url(post[\"id\"]), post[\"id\"], post[\"source\"])\n",
      "  File \"<ipython-input-40-2469a39ebf38>\", line 3, in get_post_comments\n",
      "    res = get(url)\n",
      "  File \"<ipython-input-30-183a6e4ee947>\", line 2, in get\n",
      "    return json.loads(requests.get(url_).text)\n",
      "  File \"C:\\Python3\\lib\\json\\__init__.py\", line 354, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"C:\\Python3\\lib\\json\\decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"C:\\Python3\\lib\\json\\decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "Exception in thread Thread-341:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Python3\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-42-22c8534da172>\", line 3, in get_comments\n",
      "    get_post_comments(build_comments_url(post[\"id\"]), post[\"id\"], post[\"source\"])\n",
      "  File \"<ipython-input-40-2469a39ebf38>\", line 3, in get_post_comments\n",
      "    res = get(url)\n",
      "  File \"<ipython-input-30-183a6e4ee947>\", line 2, in get\n",
      "    return json.loads(requests.get(url_).text)\n",
      "  File \"C:\\Python3\\lib\\json\\__init__.py\", line 354, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"C:\\Python3\\lib\\json\\decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"C:\\Python3\\lib\\json\\decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.to_sql(\"posts\", sqlite3.connect(\"data.db\"), if_exists=\"replace\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
