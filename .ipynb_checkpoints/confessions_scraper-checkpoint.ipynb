{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import bs4\n",
    "import os\n",
    "import sqlite3\n",
    "import threading\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set SCRAPE=True in order to download the data from FB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCRAPE = True\n",
    "\n",
    "UNIFIED_JSON_PATH = \"posts.json\"\n",
    "LOGGING_INTERVAL = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TOKEN = \"EAACEdEose0cBAPLVbhhTMvnqz7ZCZAVCK2ZAK561w1L9LZBlE4Om2fLmlATGZBeh0z2dGVPI7sRB2O7DckDMO42CBxNjicLhgDolWrZCBkSoxuh6eekBZCkF99MWfBw7IKUDiQnrTZBuAg6ttxJzVyTTXpHlDXmvugBfxVF4YxZCkKUR3HzUhrTd3RE6PCiAoB5wZD\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to return an empty list if string is not JSON formatted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    try:\n",
    "        return json.loads(open(path, \"r\").read())\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        return []\n",
    "\n",
    "def json_append(path, post):\n",
    "    data = read_json(path)\n",
    "    data.append(post)\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(json.dumps(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a supplemental function to simplify API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get(url_):\n",
    "    return json.loads(requests.get(url_).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define gruop ID variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TECHNION_CONFESSIONS_ID = \"134517547222780\"      # Technion - Haifa\n",
    "TAU_CONFESSIONS_ID = \"561380070875128\"           # Tel Aviv University\n",
    "IDC_CONFESSIONS_ID = \"199527394120566\"           # Beintchumi - Herzlia\n",
    "HUJI_CONFESSIONS_ID = \"323288791493138\"          # Hebrew University - Jerusalem\n",
    "BGU_CONFESSIONS_ID = \"151003595697352\"           # Ben Gurion University - Beer Sheva\n",
    "ARIEL_CONFESSIONS_ID = \"465435713853175\"         # Ariel University\n",
    "HAIFA_CONFESSIONS_ID = \"417201845375921\"         # Haifa University\n",
    "HADASSAH_CONFESSIONS_ID = \"2044836585541512\"     # Hadassah\n",
    "ORT_BRAUDE_CONFESSIONS_ID = \"1453869761388065\"   # Ort-Braude\n",
    "BAR_ILAN_CONFESSIONS_ID = \"2124618411093048\"     # Bar-Ilan\n",
    "MTA_CONFESSIONS_ID = \"157123741522094\"           # Tel Aviv-Yafo Academy\n",
    "YIZRAEL_CONFESSIONS_ID = \"1758687200848633\"      # Yizrael Valley Academy\n",
    "IDF_CONFESSIONS_ID = \"332027507300337\"           # IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authenticate to Graph API - it is preferred to use manual token from Graph API Explorer because it has better permissions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s = \"6cc937f2a9dbc9df92600f365c777d1a\"\n",
    "# i = \"652869818252649\"\n",
    "# u = \"https://graph.facebook.com/oauth/access_token?client_id={id}&client_secret={secret}&grant_type=client_credentials\"\n",
    "\n",
    "# TOKEN = get(u.format(id=i, secret=s))['access_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Graph API host and API node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOST = \"https://graph.facebook.com/\"\n",
    "API_NODE = \"v2.12/\"\n",
    "QUERY = \"?fields=created_time,message_tags,message,shares,reactions.type(LIKE).limit(0).summary(1).as(like),reactions.type(LOVE).limit(0).summary(1).as(love),reactions.type(HAHA).limit(0).summary(1).as(haha),reactions.type(WOW).limit(0).summary(1).as(wow),reactions.type(SAD).limit(0).summary(1).as(sad),reactions.type(ANGRY).limit(0).summary(1).as(angry)&limit=10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a list of the pages that are going to be scraped in a manner of (id, alias) tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAGES = [\n",
    "    (TECHNION_CONFESSIONS_ID, \"TECHNION\"),\n",
    "    (TAU_CONFESSIONS_ID, \"TAU\"),\n",
    "    (IDC_CONFESSIONS_ID, \"IDC\"),\n",
    "    (HUJI_CONFESSIONS_ID, \"HUJI\"),\n",
    "    (BGU_CONFESSIONS_ID, \"BGU\"),\n",
    "    (ARIEL_CONFESSIONS_ID, \"ARIEL\"),\n",
    "    (HAIFA_CONFESSIONS_ID, \"HAIFA\"),\n",
    "    (HADASSAH_CONFESSIONS_ID, \"HADASSAH\"),\n",
    "    (ORT_BRAUDE_CONFESSIONS_ID, \"BRAUDE\"),\n",
    "    (BAR_ILAN_CONFESSIONS_ID, \"BIU\"),\n",
    "    (MTA_CONFESSIONS_ID, \"MTA\"),\n",
    "    (YIZRAEL_CONFESSIONS_ID, \"YIZRAEL\"),\n",
    "    (IDF_CONFESSIONS_ID, \"IDF\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Container for the scraped posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "posts = []\n",
    "last_pages = {}  # This is intended for adding more posts without calling for scraped pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a supplemental builder functions for the API calls' URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_url(page_id):\n",
    "    return HOST + API_NODE + page_id + \"/posts\" + QUERY + \"&access_token={}\".format(TOKEN)\n",
    "\n",
    "def build_comments_url(post_id):\n",
    "    return HOST + API_NODE + post_id + \"/comments\" + QUERY + \"&access_token={}\".format(TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that scrapes a general object (post or comment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_object(raw_object, object_type, object_source, parent_id=None):\n",
    "    obj = {}   \n",
    "    \n",
    "    obj['type'] = object_type\n",
    "    obj['source'] = object_source\n",
    "    \n",
    "    obj['id'] = raw_object['id']\n",
    "    obj['parent_id'] = parent_id\n",
    "    \n",
    "    try:\n",
    "        obj['message'] = raw_object['message']\n",
    "    except KeyError:\n",
    "        obj['message'] = ''\n",
    "\n",
    "    obj['created_time'] = raw_object['created_time']\n",
    "\n",
    "    like = raw_object[\"like\"][\"summary\"][\"total_count\"]\n",
    "    love = raw_object[\"love\"][\"summary\"][\"total_count\"]\n",
    "    haha = raw_object[\"haha\"][\"summary\"][\"total_count\"]\n",
    "    wow = raw_object[\"wow\"][\"summary\"][\"total_count\"]\n",
    "    sad = raw_object[\"sad\"][\"summary\"][\"total_count\"]\n",
    "    angry = raw_object[\"angry\"][\"summary\"][\"total_count\"]\n",
    "\n",
    "    obj['like'] = like\n",
    "    obj['love'] = love\n",
    "    obj['haha'] = haha\n",
    "    obj['wow'] = wow\n",
    "    obj['sad'] = sad\n",
    "    obj['angry'] = angry\n",
    "    \n",
    "    obj['total_reactions'] = sum([like, love, haha, wow, sad, angry])\n",
    "    \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a fumction that will paginate through the posts of a URL and scrape them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_posts(url, source):\n",
    "    res = get(url)\n",
    "    if 'data' in res:\n",
    "        for i, raw_post in enumerate(res['data']):\n",
    "            post = query_object(raw_post, \"POST\", source)\n",
    "            posts.append(post)\n",
    "            if len(posts) % LOGGING_INTERVAL == 0:\n",
    "                print(\"{} is on item #{}\".format(source, len(posts)))\n",
    "    if 'paging' in res:\n",
    "        if 'next' in res['paging']:\n",
    "            last_pages[source] = url\n",
    "            return get_posts(res['paging']['next'], source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_tag(raw_tag, parent_id, parent_source):\n",
    "    tag = {}\n",
    "    \n",
    "    tag[\"parent_id\"] = parent_id\n",
    "    tag[\"source\"] = parent_source\n",
    "    tag[\"type\"] = \"TAG\"\n",
    "    \n",
    "    try:\n",
    "        tag[\"tagged_user_id\"] = raw_tag[\"id\"]\n",
    "    except KeyError:\n",
    "        tag[\"tagged_user_id\"] = None\n",
    "        \n",
    "    try:\n",
    "        tag[\"tagged_user_name\"] = raw_tag[\"name\"]\n",
    "    except KeyError:\n",
    "        tag[\"tagged_user_name\"] = None\n",
    "            \n",
    "    \n",
    "    try:\n",
    "        tag[\"tagged_user_type\"] = raw_tag[\"type\"]\n",
    "    except KeyError:\n",
    "        tag[\"tagged_user_type\"] = None\n",
    "            \n",
    "    \n",
    "    return tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that will call the API for each post comments, scrape them and get their tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_post_comments(url, post_id, post_source):\n",
    "    json_path = \"{}.json\".format(post_source)\n",
    "    res = get(url)\n",
    "    if 'data' in res:\n",
    "        for raw_comment in res['data']:\n",
    "            comment = query_object(raw_comment, \"COMMENT\", post_source, parent_id=post_id)\n",
    "            posts.append(comment)\n",
    "            \n",
    "            if raw_comment.get(\"message_tags\"):\n",
    "                for raw_tag in raw_comment.get(\"message_tags\"):\n",
    "                    tag = parse_tag(raw_tag, raw_comment[\"id\"], post_source)\n",
    "                    posts.append(tag)\n",
    "            \n",
    "            if len(posts) % LOGGING_INTERVAL == 0:\n",
    "                print(\"{} is on item #{}\".format(post_source, len(posts)))\n",
    "            \n",
    "    if 'paging' in res:\n",
    "        if 'next' in res['paging']:\n",
    "            return get_post_comments(res['paging']['next'], post_id, post_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, create a function that will scrapes all of the posts' comments and comment tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    n = max(1, n)\n",
    "    return (l[i:i+n] for i in range(0, len(l), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_comments(posts_list):\n",
    "    for post in posts_list:\n",
    "        get_post_comments(build_comments_url(post[\"id\"]), post[\"id\"], post[\"source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use threading to query each Facebook Group in a different thread - this is the worker funciton:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If SCRAPE, the script will run the threads (stop them using >>taskkill /f /im -\"python.exe\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if SCRAPE:\n",
    "    \n",
    "    threads = []\n",
    "    \n",
    "    for node, name in PAGES:\n",
    "        t = threading.Thread(target=get_posts, args=(build_url(node), name,))\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "    \n",
    "    for t in threads:\n",
    "        t.join()\n",
    "        \n",
    "else:\n",
    "    posts = pd.read_csv(\"posts.csv\").to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"posts.json\", \"w\") as f:\n",
    "    f.write(json.dumps(posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SCRAPE:\n",
    "    \n",
    "    threads = []\n",
    "    \n",
    "    print(\"[II] Scraping comments...\")\n",
    "    for posts_list in chunks(posts, 20):\n",
    "        t = threading.Thread(target=get_comments, args=(posts_list,))\n",
    "        threads.append(t)\n",
    "        t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "df = pd.read_sql(\"select * from posts\", sqlite3.connect(\"data.db\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract manual post id from the posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>angry</th>\n",
       "      <th>created_time</th>\n",
       "      <th>haha</th>\n",
       "      <th>id</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>message</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>sad</th>\n",
       "      <th>source</th>\n",
       "      <th>tagged_user_id</th>\n",
       "      <th>tagged_user_name</th>\n",
       "      <th>tagged_user_type</th>\n",
       "      <th>total_reactions</th>\n",
       "      <th>type</th>\n",
       "      <th>wow</th>\n",
       "      <th>page_id</th>\n",
       "      <th>reply_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-02-18T09:45:00+0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134517547222780_147254925949042</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>אני גרה במעונות, ואוהבת לשיר במקלחת. השכנים ב...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TECHNION</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>24.0</td>\n",
       "      <td>POST</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#2736</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-02-18T09:40:00+0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134517547222780_147254705949064</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>טוב, אז חייבת להיות תגובה נשית לבחור שהתוודה ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TECHNION</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>16.0</td>\n",
       "      <td>POST</td>\n",
       "      <td>1.0</td>\n",
       "      <td>#2735</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-02-18T09:35:00+0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134517547222780_147254525949082</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>בן הזוג שלי מדהים, אבל מול החברים שלו הוא תמי...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TECHNION</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10.0</td>\n",
       "      <td>POST</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#2734</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-02-18T09:30:00+0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134517547222780_147254145949120</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>אני מרגישה שאין לי חשק לדבר כבר הרבה זמן, כל ...</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TECHNION</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>14.0</td>\n",
       "      <td>POST</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#2733</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-02-18T09:25:00+0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>134517547222780_147253585949176</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>אני מנחה קבוצת פרויקט, יש שם בחורה כל כך יפה ...</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TECHNION</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>21.0</td>\n",
       "      <td>POST</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#2732</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  angry              created_time  haha  \\\n",
       "0      0    0.0  2018-02-18T09:45:00+0000   0.0   \n",
       "1      1    0.0  2018-02-18T09:40:00+0000   2.0   \n",
       "2      2    0.0  2018-02-18T09:35:00+0000   0.0   \n",
       "3      3    0.0  2018-02-18T09:30:00+0000   0.0   \n",
       "4      4    0.0  2018-02-18T09:25:00+0000   6.0   \n",
       "\n",
       "                                id  like  love  \\\n",
       "0  134517547222780_147254925949042  22.0   2.0   \n",
       "1  134517547222780_147254705949064  13.0   0.0   \n",
       "2  134517547222780_147254525949082   9.0   0.0   \n",
       "3  134517547222780_147254145949120   6.0   6.0   \n",
       "4  134517547222780_147253585949176  11.0   0.0   \n",
       "\n",
       "                                             message parent_id  sad    source  \\\n",
       "0   אני גרה במעונות, ואוהבת לשיר במקלחת. השכנים ב...      None  0.0  TECHNION   \n",
       "1   טוב, אז חייבת להיות תגובה נשית לבחור שהתוודה ...      None  0.0  TECHNION   \n",
       "2   בן הזוג שלי מדהים, אבל מול החברים שלו הוא תמי...      None  1.0  TECHNION   \n",
       "3   אני מרגישה שאין לי חשק לדבר כבר הרבה זמן, כל ...      None  2.0  TECHNION   \n",
       "4   אני מנחה קבוצת פרויקט, יש שם בחורה כל כך יפה ...      None  4.0  TECHNION   \n",
       "\n",
       "  tagged_user_id tagged_user_name tagged_user_type  total_reactions  type  \\\n",
       "0           None             None             None             24.0  POST   \n",
       "1           None             None             None             16.0  POST   \n",
       "2           None             None             None             10.0  POST   \n",
       "3           None             None             None             14.0  POST   \n",
       "4           None             None             None             21.0  POST   \n",
       "\n",
       "   wow page_id reply_to  \n",
       "0  0.0   #2736      NaN  \n",
       "1  1.0   #2735      NaN  \n",
       "2  0.0   #2734      NaN  \n",
       "3  0.0   #2733      NaN  \n",
       "4  0.0   #2732      NaN  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_REGEX = \"(#\\d+|\\d+#){1}\"\n",
    "df[\"page_id\"] = df[\"message\"].str.findall(ID_REGEX).str.get(0)\n",
    "df[\"message\"].str\n",
    "df[\"reply_to\"] = df[\"message\"].str.findall(ID_REGEX).str.get(1)\n",
    "df[\"message\"] = df[\"message\"].str.replace(ID_REGEX, \"\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a clean message column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['clean_message'] = df['message'].str.replace(\"[^א-ת ]\", \"\")\n",
    "df['clean_message'] = df['clean_message'].str.replace(\"[\\s]\", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export to SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_sql(\"posts\", sqlite3.connect(\"data.db\"), if_exists=\"replace\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
