{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import bs4\n",
    "import os\n",
    "import sqlite3\n",
    "import threading\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set SCRAPE=True in order to download the data from FB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCRAPE = True\n",
    "\n",
    "UNIFIED_JSON_PATH = \"posts.json\"\n",
    "LOGGING_INTERVAL = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to return an empty list if string is not JSON formatted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    try:\n",
    "        return json.loads(open(path, \"r\").read())\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        return []\n",
    "\n",
    "def json_append(path, post):\n",
    "    data = read_json(path)\n",
    "    data.append(post)\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(json.dumps(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a supplemental function to simplify API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get(url_):\n",
    "    return json.loads(requests.get(url_).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define gruop ID variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TECHNION_CONFESSIONS_ID = \"134517547222780\"      # Technion - Haifa\n",
    "TAU_CONFESSIONS_ID = \"561380070875128\"           # Tel Aviv University\n",
    "IDC_CONFESSIONS_ID = \"199527394120566\"           # Beintchumi - Herzlia\n",
    "HUJI_CONFESSIONS_ID = \"323288791493138\"          # Hebrew University - Jerusalem\n",
    "BGU_CONFESSIONS_ID = \"151003595697352\"           # Ben Gurion University - Beer Sheva\n",
    "ARIEL_CONFESSIONS_ID = \"465435713853175\"         # Ariel University\n",
    "HAIFA_CONFESSIONS_ID = \"417201845375921\"         # Haifa University\n",
    "HADASSAH_CONFESSIONS_ID = \"2044836585541512\"     # Hadassah\n",
    "ORT_BRAUDE_CONFESSIONS_ID = \"1453869761388065\"   # Ort-Braude\n",
    "BAR_ILAN_CONFESSIONS_ID = \"2124618411093048\"     # Bar-Ilan\n",
    "IDF_CONFESSIONS_ID = \"332027507300337\"           # IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authenticate to Graph API - it is preferred to use manual token from Graph API Explorer because it has better permissions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TOKEN = \"EAACEdEose0cBAIeZCu01mBf75V3cfseJE0BmiNFw3LMoJQGdFgQ8ocH0PXph3Bi4GnxEYvjkArIdZAGAUzDHloEpwMgAc2qOCoaWuIO8vbnNOSCR1BNe4dag4BPMZAZARNOlq1TUS1ZAHjBdtIkRSnF0FtNt4pJ2us4x4OBUQB15gGcnJvKePXtMuYXD2KYcZD\"\n",
    "\n",
    "# s = \"6cc937f2a9dbc9df92600f365c777d1a\"\n",
    "# i = \"652869818252649\"\n",
    "# u = \"https://graph.facebook.com/oauth/access_token?client_id={id}&client_secret={secret}&grant_type=client_credentials\"\n",
    "\n",
    "# TOKEN = get(u.format(id=i, secret=s))['access_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Graph API host and API node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOST = \"https://graph.facebook.com/\"\n",
    "API_NODE = \"v2.12/\"\n",
    "QUERY = \"?fields=created_time,message_tags,message,shares,reactions.type(LIKE).limit(0).summary(1).as(like),reactions.type(LOVE).limit(0).summary(1).as(love),reactions.type(HAHA).limit(0).summary(1).as(haha),reactions.type(WOW).limit(0).summary(1).as(wow),reactions.type(SAD).limit(0).summary(1).as(sad),reactions.type(ANGRY).limit(0).summary(1).as(angry)&limit=10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a list of the pages that are going to be scraped in a manner of (id, alias) tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PAGES = [\n",
    "#     (TECHNION_CONFESSIONS_ID, \"TECHNION\"),\n",
    "#     (TAU_CONFESSIONS_ID, \"TAU\"),\n",
    "#     (IDC_CONFESSIONS_ID, \"IDC\"),\n",
    "#     (HUJI_CONFESSIONS_ID, \"HUJI\"),\n",
    "#     (BGU_CONFESSIONS_ID, \"BGU\"),\n",
    "#     (ARIEL_CONFESSIONS_ID, \"ARIEL\"),\n",
    "#     (HAIFA_CONFESSIONS_ID, \"HAIFA\"),\n",
    "#     (HADASSAH_CONFESSIONS_ID, \"HADASSAH\"),\n",
    "#     (ORT_BRAUDE_CONFESSIONS_ID, \"BRAUDE\"),\n",
    "#     (BAR_ILAN_CONFESSIONS_ID, \"BIU\"),\n",
    "#     (IDF_CONFESSIONS_ID, \"IDF\"),\n",
    "# ]\n",
    "\n",
    "PAGES = [\n",
    "    (IDF_CONFESSIONS_ID, \"IDF\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Container for the scraped posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "posts = []\n",
    "last_pages = {}  # This is intended for adding more posts without calling for scraped pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a supplemental builder functions for the API calls' URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_url(page_id):\n",
    "    return HOST + API_NODE + page_id + \"/posts\" + QUERY + \"&access_token={}\".format(TOKEN)\n",
    "\n",
    "def build_comments_url(post_id):\n",
    "    return HOST + API_NODE + post_id + \"/comments\" + QUERY + \"&access_token={}\".format(TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that scrapes a general object (post or comment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_object(raw_object, object_type, object_source, parent_id=None):\n",
    "    obj = {}   \n",
    "    \n",
    "    obj['type'] = object_type\n",
    "    obj['source'] = object_source\n",
    "    \n",
    "    obj['id'] = raw_object['id']\n",
    "    obj['parent_id'] = parent_id\n",
    "    \n",
    "    try:\n",
    "        obj['message'] = raw_object['message']\n",
    "    except KeyError:\n",
    "        obj['message'] = ''\n",
    "\n",
    "    obj['created_time'] = raw_object['created_time']\n",
    "\n",
    "    like = raw_object[\"like\"][\"summary\"][\"total_count\"]\n",
    "    love = raw_object[\"love\"][\"summary\"][\"total_count\"]\n",
    "    haha = raw_object[\"haha\"][\"summary\"][\"total_count\"]\n",
    "    wow = raw_object[\"wow\"][\"summary\"][\"total_count\"]\n",
    "    sad = raw_object[\"sad\"][\"summary\"][\"total_count\"]\n",
    "    angry = raw_object[\"angry\"][\"summary\"][\"total_count\"]\n",
    "\n",
    "    obj['like'] = like\n",
    "    obj['love'] = love\n",
    "    obj['haha'] = haha\n",
    "    obj['wow'] = wow\n",
    "    obj['sad'] = sad\n",
    "    obj['angry'] = angry\n",
    "    \n",
    "    obj['total_reactions'] = sum([like, love, haha, wow, sad, angry])\n",
    "    \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a fumction that will paginate through the posts of a URL and scrape them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_posts(url, source):\n",
    "    res = get(url)\n",
    "    if 'data' in res:\n",
    "        for i, raw_post in enumerate(res['data']):\n",
    "            post = query_object(raw_post, \"POST\", source)\n",
    "            posts.append(post)\n",
    "            if len(posts) % LOGGING_INTERVAL == 0:\n",
    "                print(\"{} is on item #{}\".format(source, len(posts)))\n",
    "    if 'paging' in res:\n",
    "        if 'next' in res['paging']:\n",
    "            last_pages[source] = url\n",
    "            return get_posts(res['paging']['next'], source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_tag(raw_tag, parent_id, parent_source):\n",
    "    tag = {}\n",
    "    \n",
    "    tag[\"parent_id\"] = parent_id\n",
    "    tag[\"source\"] = parent_source\n",
    "    tag[\"type\"] = \"TAG\"\n",
    "    \n",
    "    try:\n",
    "        tag[\"tagged_user_id\"] = raw_tag[\"id\"]\n",
    "    except KeyError:\n",
    "        tag[\"tagged_user_id\"] = None\n",
    "        \n",
    "    try:\n",
    "        tag[\"tagged_user_name\"] = raw_tag[\"name\"]\n",
    "    except KeyError:\n",
    "        tag[\"tagged_user_name\"] = None\n",
    "            \n",
    "    \n",
    "    try:\n",
    "        tag[\"tagged_user_type\"] = raw_tag[\"type\"]\n",
    "    except KeyError:\n",
    "        tag[\"tagged_user_type\"] = None\n",
    "            \n",
    "    \n",
    "    return tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that will call the API for each post comments, scrape them and get their tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_post_comments(url, post_id, post_source):\n",
    "    json_path = \"{}.json\".format(post_source)\n",
    "    res = get(url)\n",
    "    if 'data' in res:\n",
    "        for raw_comment in res['data']:\n",
    "            comment = query_object(raw_comment, \"COMMENT\", post_source, parent_id=post_id)\n",
    "            posts.append(comment)\n",
    "            \n",
    "            if raw_comment.get(\"message_tags\"):\n",
    "                for raw_tag in raw_comment.get(\"message_tags\"):\n",
    "                    tag = parse_tag(raw_tag, raw_comment[\"id\"], post_source)\n",
    "                    posts.append(tag)\n",
    "            \n",
    "            if len(posts) % LOGGING_INTERVAL == 0:\n",
    "                print(\"{} is on item #{}\".format(post_source, len(posts)))\n",
    "            \n",
    "    if 'paging' in res:\n",
    "        if 'next' in res['paging']:\n",
    "            return get_post_comments(res['paging']['next'], post_id, post_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, create a function that will scrapes all of the posts' comments and comment tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    n = max(1, n)\n",
    "    return (l[i:i+n] for i in range(0, len(l), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_comments(posts_list):\n",
    "    for post in posts_list:\n",
    "        get_post_comments(build_comments_url(post[\"id\"]), post[\"id\"], post[\"source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use threading to query each Facebook Group in a different thread - this is the worker funciton:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If SCRAPE, the script will run the threads (stop them using >>taskkill /f /im -\"python.exe\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if SCRAPE:\n",
    "    \n",
    "    threads = []\n",
    "    \n",
    "    for node, name in PAGES:\n",
    "        t = threading.Thread(target=get_posts, args=(build_url(node), name,))\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "    \n",
    "    for t in threads:\n",
    "        t.join()\n",
    "        \n",
    "else:\n",
    "    posts = pd.read_csv(\"posts.csv\").to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"posts.json\", \"w\") as f:\n",
    "    f.write(json.dumps(posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[II] Scraping comments...\n"
     ]
    }
   ],
   "source": [
    "if SCRAPE:\n",
    "    \n",
    "    threads = []\n",
    "    \n",
    "    print(\"[II] Scraping comments...\")\n",
    "    for posts_list in chunks(posts, 20):\n",
    "        t = threading.Thread(target=get_comments, args=(posts_list,))\n",
    "        threads.append(t)\n",
    "        t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "701"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_sql(\"posts\", sqlite3.connect(\"data.db\"), if_exists=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angry</th>\n",
       "      <th>created_time</th>\n",
       "      <th>haha</th>\n",
       "      <th>id</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>message</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>sad</th>\n",
       "      <th>source</th>\n",
       "      <th>total_reactions</th>\n",
       "      <th>type</th>\n",
       "      <th>wow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-02-14T13:53:36+0000</td>\n",
       "      <td>0</td>\n",
       "      <td>332027507300337_336284580207963</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>#195 בסיום בה״ד 1 העמדנו מסדר על המגורים והיית...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>IDF</td>\n",
       "      <td>3</td>\n",
       "      <td>POST</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-02-14T13:53:10+0000</td>\n",
       "      <td>0</td>\n",
       "      <td>332027507300337_336284503541304</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#194 פעם ישנתי ערום בשק\"ש בשטח והיה לי קרי ליל...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>IDF</td>\n",
       "      <td>1</td>\n",
       "      <td>POST</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-02-14T13:52:27+0000</td>\n",
       "      <td>0</td>\n",
       "      <td>332027507300337_336284160208005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#193 פעם אחת בחדר שלי צחקנו בחדר ואז אחד ממי ש...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>IDF</td>\n",
       "      <td>0</td>\n",
       "      <td>POST</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-02-14T13:51:53+0000</td>\n",
       "      <td>0</td>\n",
       "      <td>332027507300337_336283333541421</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#192 אני עתודאי, וכאשר עשינו טירונות עתודאים, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>IDF</td>\n",
       "      <td>1</td>\n",
       "      <td>POST</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-02-14T11:05:34+0000</td>\n",
       "      <td>0</td>\n",
       "      <td>332027507300337_336227386880349</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>#191 אימון גדודי בגולן, אני בערך חודש וחצי לפנ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>IDF</td>\n",
       "      <td>7</td>\n",
       "      <td>POST</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   angry              created_time  haha                               id  \\\n",
       "0      0  2018-02-14T13:53:36+0000     0  332027507300337_336284580207963   \n",
       "1      0  2018-02-14T13:53:10+0000     0  332027507300337_336284503541304   \n",
       "2      0  2018-02-14T13:52:27+0000     0  332027507300337_336284160208005   \n",
       "3      0  2018-02-14T13:51:53+0000     0  332027507300337_336283333541421   \n",
       "4      0  2018-02-14T11:05:34+0000     0  332027507300337_336227386880349   \n",
       "\n",
       "   like  love                                            message parent_id  \\\n",
       "0     3     0  #195 בסיום בה״ד 1 העמדנו מסדר על המגורים והיית...      None   \n",
       "1     1     0  #194 פעם ישנתי ערום בשק\"ש בשטח והיה לי קרי ליל...      None   \n",
       "2     0     0  #193 פעם אחת בחדר שלי צחקנו בחדר ואז אחד ממי ש...      None   \n",
       "3     1     0  #192 אני עתודאי, וכאשר עשינו טירונות עתודאים, ...      None   \n",
       "4     7     0  #191 אימון גדודי בגולן, אני בערך חודש וחצי לפנ...      None   \n",
       "\n",
       "   sad source  total_reactions  type  wow  \n",
       "0    0    IDF                3  POST    0  \n",
       "1    0    IDF                1  POST    0  \n",
       "2    0    IDF                0  POST    0  \n",
       "3    0    IDF                1  POST    0  \n",
       "4    0    IDF                7  POST    0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
